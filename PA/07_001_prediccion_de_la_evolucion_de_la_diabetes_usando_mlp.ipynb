{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-001_prediccion_de_la_evolucion_de_la_diabetes_usando_mlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrYmadMSOB6"
      },
      "source": [
        "# Predicción de la evolución de la diabetes en pacientes usando MLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwtE_okTSkAy"
      },
      "source": [
        "Se desea construir um modelo de regresión no lineal (redes neuronales artificiales) que permita pronósticar el progreso de la diabetes con un horizonte de doce meses con base en variables físicas y pruebas de laboratorio. Véase https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwP-gWqzSm2L"
      },
      "source": [
        "En este problema se tiene una base de datos de diez variables base (edad, sexo, índice de masa corporal, presión arterial, y seis variables medidas en sangre) para 442 pacientes, y un índice que mide el progreso de la diabetes un año después de la prueba. La columna Y es la variable explicada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMWGUTBYSvre"
      },
      "source": [
        "\n",
        "# La muestra se encuentra dividida en tres partes:\n",
        "#\n",
        "#   * X_train, y_true_train: es la muestra para estimar los parametros optimos\n",
        "#\n",
        "#   * X_test, y_true_test: es la muestra para seleccionar la mejor configuración\n",
        "#\n",
        "#   * X_val, y_true_val: es la muestra para probar el modelo en productivo\n",
        "#\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pytest\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/diabetes.csv\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Use la muestra (X_train, y_true_train) para la estimación\n",
        "# de los pesos óptimos de la red neuronal.\n",
        "#\n",
        "# Seleccione el modelo óptimo como aquel que minimice el error\n",
        "# cuadrático medio para la muestra (X_test, y_true_test).\n",
        "#\n",
        "# Considere únicamente modelos desde una (1) hasta (5) \n",
        "# neuronas en la capa oculta. Considere únicamente las\n",
        "# siguientes semillas para inicializar la red neuronal\n",
        "# 1000, 1001, 1002, 1003, 1004, 1005.\n",
        "#\n",
        "# Compute el error cuadrático medio para la muestra\n",
        "# (X_val, y_true_val). Esta muestra representa la operación\n",
        "# del modelo en productio\n",
        "# \n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "scaler = MinMaxScaler(feature_range=(0,0.5)) #Escalamos los datos del DF para que sean estandares\n",
        "df_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "X = df_norm.iloc[:,:-1]\n",
        "y = df_norm['target']\n",
        "\n",
        "#Particion de los datos\n",
        "X_train, X_test, y_true_train, y_true_test = train_test_split(X, y, test_size=0.3,random_state=177) #Entrenamos los datos\n",
        "X_val, X_test, y_true_val, y_true_test = train_test_split(X_test,y_true_test, test_size=0.5,random_state=177) #Entrenamos los datos\n",
        "\n",
        "param_grid2 = {#Aplicamos GrindSearch\n",
        "                \"hidden_layer_sizes\": [(1,),(2,),(3,),(4,),(5,)],\n",
        "                \"random_state\": [1000,1001,1002,1004,1005],\n",
        "    }\n",
        "\n",
        "#Creamos el modelo\n",
        "m2 = MLPRegressor(activation=\"identity\",\n",
        "    learning_rate_init=0.001,\n",
        "    solver='adam',\n",
        "    max_iter=100) \n",
        "\n",
        "# Creamos el GridSearc\n",
        "grid_search = GridSearchCV(estimator = m2, param_grid=param_grid2, cv=5) \n",
        "# Entrenamos con el Gridsearch\n",
        "grid_search.fit(X_train, y_true_train)\n",
        "\n",
        "# Miramos el mejor estimador\n",
        "#print('Mejor Estimador : ', grid_search.best_estimator_)\n",
        "#print('Mejores Parametros : ', grid_search.best_params_)\n",
        "#print('Mejor score : ',grid_search.best_score_)\n",
        "\n",
        "# Hacemos la prediccion\n",
        "y_pred = grid_search.predict(X_val)\n",
        "mse_val = mean_squared_error(y_true_val,y_pred)\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "pytest.approx(mse_val, 0.0001) == 0.009535\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8PJnxaKFmK",
        "outputId": "bad11f5d-2abe-4e3a-c750-19c7e315b5aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}